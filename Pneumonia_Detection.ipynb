{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d1f7968f7b8f47209f2ecc70b1551974": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10b20ff711324c38a1cf15801091c799",
              "IPY_MODEL_59072450a8dd42309d438279ed41dc68",
              "IPY_MODEL_8c24e4ed671a4e76a6d4dfdad05fd44e"
            ],
            "layout": "IPY_MODEL_14cfe59dd0574923b49702e63fee6721"
          }
        },
        "10b20ff711324c38a1cf15801091c799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b1be4490bc6488ca4db1d010814f854",
            "placeholder": "​",
            "style": "IPY_MODEL_1fcdc18c7c7c43f5907899d385788467",
            "value": "Map: 100%"
          }
        },
        "59072450a8dd42309d438279ed41dc68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90337ae499f442e3a858ee89fa2b8016",
            "max": 10200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3aa83bf0fd45478cb11b9c82a5399be4",
            "value": 10200
          }
        },
        "8c24e4ed671a4e76a6d4dfdad05fd44e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_073d76d745fd4e0a9a538195be421109",
            "placeholder": "​",
            "style": "IPY_MODEL_dacc91401f2f42a4b66391a87e140b23",
            "value": " 10200/10200 [00:01&lt;00:00, 10742.04 examples/s]"
          }
        },
        "14cfe59dd0574923b49702e63fee6721": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b1be4490bc6488ca4db1d010814f854": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fcdc18c7c7c43f5907899d385788467": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90337ae499f442e3a858ee89fa2b8016": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3aa83bf0fd45478cb11b9c82a5399be4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "073d76d745fd4e0a9a538195be421109": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dacc91401f2f42a4b66391a87e140b23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b43ca1d60e664c539b306c7756ace589": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a36032faf71f4dd38f31ee5ff64fb6aa",
              "IPY_MODEL_ba3ec145ac9f4eb29575dbe4d33255fe",
              "IPY_MODEL_161ed0bf0fc2435c8a0e83146359f706"
            ],
            "layout": "IPY_MODEL_91701a0a604b4c598ea47222e5d060ad"
          }
        },
        "a36032faf71f4dd38f31ee5ff64fb6aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbfbfd3f647c4070ab654aa78df25890",
            "placeholder": "​",
            "style": "IPY_MODEL_1e6bba5dfb8348d7a1f74a0f0ade1359",
            "value": "Map: 100%"
          }
        },
        "ba3ec145ac9f4eb29575dbe4d33255fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79be2d467bf940a08204afb261cebd3f",
            "max": 1800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5476837eddd94e5b943f8302bec1d3a8",
            "value": 1800
          }
        },
        "161ed0bf0fc2435c8a0e83146359f706": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d517b70002b4e9eb68478fb5bfc8615",
            "placeholder": "​",
            "style": "IPY_MODEL_760b542c287c411e9b32199ed7d77bd9",
            "value": " 1800/1800 [00:00&lt;00:00, 7793.71 examples/s]"
          }
        },
        "91701a0a604b4c598ea47222e5d060ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbfbfd3f647c4070ab654aa78df25890": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e6bba5dfb8348d7a1f74a0f0ade1359": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79be2d467bf940a08204afb261cebd3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5476837eddd94e5b943f8302bec1d3a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d517b70002b4e9eb68478fb5bfc8615": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "760b542c287c411e9b32199ed7d77bd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adityaaz10/Pnuemonia_detection_model/blob/main/Pneumonia_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPZEtUckU4uu"
      },
      "outputs": [],
      "source": [
        "!pip -q install torch torchvision --extra-index-url https://download.pytorch.org/whl/cu121\n",
        "!pip -q install transformers datasets accelerate timm\n",
        "!pip -q install kaggle pydicom pillow opencv-python scikit-learn matplotlib seaborn grad-cam gradio\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch; torch.cuda.is_available()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-ynIjEYVeVW",
        "outputId": "0074eb07-8de0-401a-ef1b-4f90be72e049"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "i6FB70rlbfdA",
        "outputId": "a99eaee1-c20f-4018-fc03-c206e6aff959"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-03903865-c2ac-43a6-b378-9adf958e11a7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-03903865-c2ac-43a6-b378-9adf958e11a7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"adimukherjee10\",\"key\":\"3651aa66b080724db637883a25ed89c8\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil\n",
        "os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "shutil.move('/content/kaggle.json', '/root/.kaggle/kaggle.json')\n",
        "os.chmod('/root/.kaggle/kaggle.json', 0o600)\n"
      ],
      "metadata": {
        "id": "c7yCHfyaVx6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c rsna-pneumonia-detection-challenge -p /content/rsna\n",
        "import zipfile, glob\n",
        "for z in glob.glob('/content/rsna/*.zip'):\n",
        "    with zipfile.ZipFile(z, 'r') as zip_ref:\n",
        "        zip_ref.extractall('/content/rsna')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_ECxVijV9SL",
        "outputId": "935e603a-85a9-462b-c18b-5c99465c837d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rsna-pneumonia-detection-challenge.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install pydicom\n",
        "\n",
        "import pandas as pd, numpy as np, os, cv2, pydicom\n",
        "from tqdm import tqdm\n",
        "\n",
        "DICOM_DIR = '/content/rsna/stage_2_train_images'\n",
        "LABELS_CSV = '/content/rsna/stage_2_train_labels.csv'\n",
        "OUT_DIR = '/content/rsna_png'\n",
        "os.makedirs(f'{OUT_DIR}/images', exist_ok=True)\n",
        "\n",
        "labels = pd.read_csv(LABELS_CSV)\n",
        "img_labels = labels.groupby('patientId')['Target'].max().reset_index()\n",
        "img_labels['label'] = img_labels['Target'].astype(int)\n",
        "img_labels = img_labels[['patientId','label']]\n",
        "\n",
        "# LIMIT to a manageable subset first (adjust up later)\n",
        "MAX_IMAGES = 12000  # try 4000 if still OOM; 12000 if stable\n",
        "img_labels = img_labels.sample(n=min(MAX_IMAGES, len(img_labels)), random_state=42)\n",
        "\n",
        "# Low resolution to save memory; try (160,160) or (128,128) if still OOM\n",
        "RES = 160\n",
        "\n",
        "def dicom_to_png(path, size=(RES, RES)):\n",
        "    d = pydicom.dcmread(path)\n",
        "    arr = d.pixel_array.astype(np.float32)\n",
        "    # normalize 0-255\n",
        "    arr -= arr.min()\n",
        "    if arr.max() > 0:\n",
        "        arr /= arr.max()\n",
        "    arr = (arr * 255.0).clip(0,255).astype(np.uint8)\n",
        "    arr = cv2.resize(arr, size, interpolation=cv2.INTER_AREA)\n",
        "    img3 = np.stack([arr, arr, arr], axis=-1)\n",
        "    return img3\n",
        "\n",
        "paths, ys = [], []\n",
        "for pid, y in tqdm(img_labels.values):\n",
        "    p = os.path.join(DICOM_DIR, f'{pid}.dcm')\n",
        "    if not os.path.exists(p):\n",
        "        continue\n",
        "    img = dicom_to_png(p)\n",
        "    outp = os.path.join(OUT_DIR, 'images', f'{pid}.png')\n",
        "    cv2.imwrite(outp, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
        "    paths.append(outp)\n",
        "    ys.append(int(y))\n",
        "\n",
        "meta = pd.DataFrame({'image_path': paths, 'label': ys})\n",
        "meta.to_csv(f'{OUT_DIR}/train_meta.csv', index=False)\n",
        "meta['label'].value_counts(), len(meta)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cg8RSkJ8WdTr",
        "outputId": "8de4cee4-09fe-430f-bda4-5335e057272e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12000/12000 [02:46<00:00, 72.12it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(label\n",
              " 0    9248\n",
              " 1    2752\n",
              " Name: count, dtype: int64,\n",
              " 12000)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "import pandas as pd\n",
        "\n",
        "meta = pd.read_csv('/content/rsna_png/train_meta.csv')\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.15, random_state=42)\n",
        "train_idx, val_idx = next(sss.split(meta['image_path'], meta['label']))\n",
        "train_df = meta.iloc[train_idx].reset_index(drop=True)\n",
        "val_df = meta.iloc[val_idx].reset_index(drop=True)\n",
        "\n",
        "ds_train = Dataset.from_pandas(train_df)\n",
        "ds_val = Dataset.from_pandas(val_df)\n",
        "len(ds_train), len(ds_val)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2NU09CNXTX0",
        "outputId": "8f06afba-e52a-46ef-e046-015e4ddfe2a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10200, 1800)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timm, torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "# Image transforms (match RES)\n",
        "RES = 224  # set same as preprocessing\n",
        "train_tfms = transforms.Compose([\n",
        "    transforms.Resize((RES, RES)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.25,0.25,0.25])\n",
        "])\n",
        "val_tfms = transforms.Compose([\n",
        "    transforms.Resize((RES, RES)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.25,0.25,0.25])\n",
        "])\n",
        "\n",
        "# Lazy loader functions\n",
        "def load_image(example):\n",
        "    example['image'] = example['image_path']\n",
        "    return example\n",
        "\n",
        "ds_train = ds_train.map(load_image)\n",
        "ds_val = ds_val.map(load_image)\n",
        "\n",
        "# Minimal collate to load+transform per batch\n",
        "def collate_fn(batch, train=True):\n",
        "    imgs = []\n",
        "    labels = []\n",
        "    for ex in batch:\n",
        "        img = Image.open(ex['image']).convert('RGB')\n",
        "        img = (train_tfms if train else val_tfms)(img)\n",
        "        imgs.append(img)\n",
        "        labels.append(int(ex['label']))\n",
        "    return {'pixel_values': torch.stack(imgs), 'labels': torch.tensor(labels, dtype=torch.long)}\n",
        "\n",
        "# Model\n",
        "num_classes = 2\n",
        "model = timm.create_model('resnet18', pretrained=True, num_classes=num_classes)\n",
        "model = model.cuda()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "d1f7968f7b8f47209f2ecc70b1551974",
            "10b20ff711324c38a1cf15801091c799",
            "59072450a8dd42309d438279ed41dc68",
            "8c24e4ed671a4e76a6d4dfdad05fd44e",
            "14cfe59dd0574923b49702e63fee6721",
            "4b1be4490bc6488ca4db1d010814f854",
            "1fcdc18c7c7c43f5907899d385788467",
            "90337ae499f442e3a858ee89fa2b8016",
            "3aa83bf0fd45478cb11b9c82a5399be4",
            "073d76d745fd4e0a9a538195be421109",
            "dacc91401f2f42a4b66391a87e140b23",
            "b43ca1d60e664c539b306c7756ace589",
            "a36032faf71f4dd38f31ee5ff64fb6aa",
            "ba3ec145ac9f4eb29575dbe4d33255fe",
            "161ed0bf0fc2435c8a0e83146359f706",
            "91701a0a604b4c598ea47222e5d060ad",
            "fbfbfd3f647c4070ab654aa78df25890",
            "1e6bba5dfb8348d7a1f74a0f0ade1359",
            "79be2d467bf940a08204afb261cebd3f",
            "5476837eddd94e5b943f8302bec1d3a8",
            "1d517b70002b4e9eb68478fb5bfc8615",
            "760b542c287c411e9b32199ed7d77bd9"
          ]
        },
        "id": "T_uyRIdTXZQp",
        "outputId": "1a6ba4c9-f6f0-4a2b-f9a5-e6454b86cedb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10200 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d1f7968f7b8f47209f2ecc70b1551974"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1800 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b43ca1d60e664c539b306c7756ace589"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, zipfile\n",
        "\n",
        "KAGGLE_DATASET = 'himanshu007121/coughclassifier-trial'\n",
        "DATA_DIR = './coughclassifier_trial'\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "os.system(f'kaggle datasets download -d {KAGGLE_DATASET} -p {DATA_DIR}')\n",
        "for file in os.listdir(DATA_DIR):\n",
        "    if file.endswith('.zip'):\n",
        "        with zipfile.ZipFile(os.path.join(DATA_DIR, file), 'r') as zip_ref:\n",
        "            zip_ref.extractall(DATA_DIR)\n"
      ],
      "metadata": {
        "id": "ixt70_6ubooo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(meta.columns)\n",
        "\n"
      ],
      "metadata": {
        "id": "bVdn9E5_foXr",
        "outputId": "1254bb0f-70c8-491c-afd0-35d7809361b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['chroma_stft', 'rmse', 'spectral_centroid', 'spectral_bandwidth',\n",
            "       'rolloff', 'zero_crossing_rate', 'mfcc1', 'mfcc2', 'mfcc3', 'mfcc4',\n",
            "       'mfcc5', 'mfcc6', 'mfcc7', 'mfcc8', 'mfcc9', 'mfcc10', 'mfcc11',\n",
            "       'mfcc12', 'mfcc13', 'mfcc14', 'mfcc15', 'mfcc16', 'mfcc17', 'mfcc18',\n",
            "       'mfcc19', 'mfcc20', 'label'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LABEL_CSV = os.path.join(DATA_DIR, 'Smote_data.csv')\n",
        "meta = pd.read_csv(LABEL_CSV)\n",
        "print(meta.columns)\n",
        "print(meta.head())\n",
        "\n",
        "# Suppose columns are 'audio', 'label' where label: 1=positive/covid, 0=negative/healthy\n",
        "filtered = meta.copy()\n",
        "filtered.to_csv(os.path.join(DATA_DIR, 'filtered_labels.csv'), index=False)\n"
      ],
      "metadata": {
        "id": "K8e9diwGdgl4",
        "outputId": "a75d8c38-2dec-4e1f-ae70-b7a832f210ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['chroma_stft', 'rmse', 'spectral_centroid', 'spectral_bandwidth',\n",
            "       'rolloff', 'zero_crossing_rate', 'mfcc1', 'mfcc2', 'mfcc3', 'mfcc4',\n",
            "       'mfcc5', 'mfcc6', 'mfcc7', 'mfcc8', 'mfcc9', 'mfcc10', 'mfcc11',\n",
            "       'mfcc12', 'mfcc13', 'mfcc14', 'mfcc15', 'mfcc16', 'mfcc17', 'mfcc18',\n",
            "       'mfcc19', 'mfcc20', 'label'],\n",
            "      dtype='object')\n",
            "   chroma_stft      rmse  spectral_centroid  spectral_bandwidth   rolloff  \\\n",
            "0     0.975000 -0.225520          -1.133697           -1.419965 -1.341559   \n",
            "1     1.138436 -1.085691           0.458562            0.432626  0.072958   \n",
            "2     0.729820 -0.463494           1.126956            0.996399  1.257855   \n",
            "3     0.079311 -0.968320          -0.561011            0.281959 -0.012494   \n",
            "4    -0.070381 -0.531515          -0.842920           -0.657277 -0.780357   \n",
            "\n",
            "   zero_crossing_rate     mfcc1     mfcc2     mfcc3     mfcc4  ...    mfcc12  \\\n",
            "0           -0.632042 -0.583560  0.898607 -0.365554 -0.259207  ... -0.657483   \n",
            "1           -0.057713 -1.792492 -0.521783  0.305802  2.225591  ...  0.293051   \n",
            "2            1.002515  0.220042 -0.866718  0.239354  0.073121  ... -0.457561   \n",
            "3           -0.915131 -0.379598  0.760281  0.619239  0.313684  ... -0.576460   \n",
            "4           -0.593184 -1.093765 -0.620821  0.698026 -0.100955  ... -0.548312   \n",
            "\n",
            "     mfcc13    mfcc14    mfcc15    mfcc16    mfcc17    mfcc18    mfcc19  \\\n",
            "0  0.391056  0.263061  0.141073  0.050127  0.140086 -0.207874  0.149673   \n",
            "1  1.700987  0.023959  1.571899  1.136404  1.256854  0.926503  1.117961   \n",
            "2 -0.106347  0.455469  0.717856  0.509769 -0.937644 -0.218431  0.345348   \n",
            "3 -1.546116 -0.915997 -0.759205  0.669422 -1.606791 -0.906112 -2.644708   \n",
            "4 -0.015434 -0.661079  0.861282 -0.577522 -0.526032 -0.558068 -0.524245   \n",
            "\n",
            "     mfcc20  label  \n",
            "0 -0.535819      1  \n",
            "1  0.811248      1  \n",
            "2 -0.942711      1  \n",
            "3 -1.166570      0  \n",
            "4 -0.962037      0  \n",
            "\n",
            "[5 rows x 27 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "SAMPLE_RATE = 22050\n",
        "N_MELS = 128\n",
        "SEG_LEN = 128\n",
        "\n",
        "class CoughAudioDataset(Dataset):\n",
        "    def __init__(self, audio_dir, label_csv):\n",
        "        self.meta = pd.read_csv(label_csv)\n",
        "        self.audio_dir = audio_dir\n",
        "        self.sr = SAMPLE_RATE\n",
        "        self.n_mels = N_MELS\n",
        "        self.seg_len = SEG_LEN\n",
        "        self.mel_transform = torchaudio.transforms.MelSpectrogram(sample_rate=self.sr, n_mels=self.n_mels)\n",
        "        self.db_transform = torchaudio.transforms.AmplitudeToDB()\n",
        "    def __len__(self):\n",
        "        return len(self.meta)\n",
        "    def pad_or_crop(self, spec):\n",
        "        if spec.shape[-1] < self.seg_len:\n",
        "            pad_amt = self.seg_len - spec.shape[-1]\n",
        "            spec = torch.nn.functional.pad(spec, (0, pad_amt))\n",
        "        else:\n",
        "            spec = spec[:, :self.seg_len]\n",
        "        return spec\n",
        "    def __getitem__(self, idx):\n",
        "        fname, label = self.meta.iloc[idx], int(self.meta.iloc[idx]['label'])\n",
        "        path = os.path.join(self.audio_dir, fname)\n",
        "        wav, sr = torchaudio.load(path)\n",
        "        if sr != self.sr:\n",
        "            wav = torchaudio.functional.resample(wav, orig_freq=sr, new_freq=self.sr)\n",
        "        if wav.shape[0] > 1:\n",
        "            wav = torch.mean(wav, dim=0, keepdim=True)\n",
        "        mel = self.mel_transform(wav)\n",
        "        mel_db = self.db_transform(mel)\n",
        "        mel_db = mel_db.squeeze()\n",
        "        mel_db = self.pad_or_crop(mel_db)\n",
        "        mel_db = mel_db.unsqueeze(0)\n",
        "        return mel_db, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "dataset = CoughAudioDataset(DATA_DIR, os.path.join(DATA_DIR, 'filtered_labels.csv'))\n",
        "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)"
      ],
      "metadata": {
        "id": "oIhYj0ekdj2t",
        "outputId": "3f5578e2-08ee-4ac9-92bc-cccd00beae79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchaudio/functional/functional.py:585: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet18\n",
        "import torch.nn as nn\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = resnet18(pretrained=True)\n",
        "model.conv1 = nn.Conv2d(1, model.conv1.out_channels, kernel_size=model.conv1.kernel_size,\n",
        "                        stride=model.conv1.stride, padding=model.conv1.padding, bias=False)\n",
        "model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "model = model.to(device)\n",
        "\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "for epoch in range(5):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for X, y in tqdm(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(X)\n",
        "        loss = criterion(out, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * X.size(0)\n",
        "    print(f\"Epoch {epoch+1}: avg loss = {total_loss / len(dataset):.4f}\")\n"
      ],
      "metadata": {
        "id": "WjRN0Jl5dkqh",
        "outputId": "26883194-9fc9-4492-ce3e-cba150c73ba6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "  0%|          | 0/37 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "join() argument must be str, bytes, or os.PathLike object, not 'Series'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2002524828.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-618746931.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mwav\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/posixpath.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/genericpath.py\u001b[0m in \u001b[0;36m_check_arg_types\u001b[0;34m(funcname, *args)\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: join() argument must be str, bytes, or os.PathLike object, not 'Series'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1XxCiDscdZY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math, numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
        "\n",
        "\n",
        "BATCH = 16  # try 16; if OOM, set 8 or 4\n",
        "ACCUM = 2   # gradient accumulation steps (effective batch = BATCH*ACCUM)\n",
        "EPOCHS = 3\n",
        "LR = 3e-4\n",
        "\n",
        "\n",
        "train_loader = DataLoader(ds_train, batch_size=BATCH, shuffle=True, collate_fn=lambda x: collate_fn(x, True), num_workers=2, pin_memory=True)\n",
        "val_loader   = DataLoader(ds_val,   batch_size=BATCH, shuffle=False, collate_fn=lambda x: collate_fn(x, False), num_workers=2, pin_memory=True)\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-2)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS*len(train_loader))\n",
        "\n",
        "\n",
        "best_auc = -1\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    running_loss = 0.0\n",
        "    for step, batch in enumerate(train_loader):\n",
        "        x = batch['pixel_values'].cuda(non_blocking=True)\n",
        "        y = batch['labels'].cuda(non_blocking=True)\n",
        "        logits = model(x)\n",
        "        loss = criterion(logits, y) / ACCUM\n",
        "        loss.backward()\n",
        "        if (step+1) % ACCUM == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            scheduler.step()\n",
        "        running_loss += loss.item() * ACCUM\n",
        "        if (step+1) % 100 == 0:\n",
        "            print(f\"epoch {epoch+1} step {step+1}/{len(train_loader)} loss {running_loss/(step+1):.4f}\")\n",
        "\n",
        "\n",
        "    # Eval\n",
        "    model.eval()\n",
        "    all_probs, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            x = batch['pixel_values'].cuda(non_blocking=True)\n",
        "            y = batch['labels'].cuda(non_blocking=True)\n",
        "            logits = model(x)\n",
        "            probs = torch.softmax(logits, dim=1)[:,1].detach().cpu().numpy()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(y.detach().cpu().numpy())\n",
        "    all_probs = np.concatenate(all_probs)\n",
        "    all_labels = np.concatenate(all_labels)\n",
        "    preds = (all_probs >= 0.5).astype(int)\n",
        "    acc = accuracy_score(all_labels, preds)\n",
        "    prec, rec, f1, _ = precision_recall_fscore_support(all_labels, preds, average='binary')\n",
        "    try:\n",
        "        auc = roc_auc_score(all_labels, all_probs)\n",
        "    except:\n",
        "        auc = float('nan')\n",
        "    print(f\"E{epoch+1}: acc={acc:.3f} rec={rec:.3f} f1={f1:.3f} auc={auc:.3f}\")\n",
        "    if auc > best_auc:\n",
        "        best_auc = auc\n",
        "        torch.save(model.state_dict(), '/content/best_resnet18.pth')\n",
        "print('Best AUC:', best_auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgfAssoQXknV",
        "outputId": "f0e4fe3e-e61c-4318-de4a-a131155b1511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 step 100/638 loss 0.4795\n",
            "epoch 1 step 200/638 loss 0.4601\n",
            "epoch 1 step 300/638 loss 0.4463\n",
            "epoch 1 step 400/638 loss 0.4373\n",
            "epoch 1 step 500/638 loss 0.4285\n",
            "epoch 1 step 600/638 loss 0.4273\n",
            "E1: acc=0.828 rec=0.545 f1=0.592 auc=0.857\n",
            "epoch 2 step 100/638 loss 0.3857\n",
            "epoch 2 step 200/638 loss 0.3841\n",
            "epoch 2 step 300/638 loss 0.3891\n",
            "epoch 2 step 400/638 loss 0.3902\n",
            "epoch 2 step 500/638 loss 0.3872\n",
            "epoch 2 step 600/638 loss 0.3866\n",
            "E2: acc=0.828 rec=0.593 f1=0.613 auc=0.861\n",
            "epoch 3 step 100/638 loss 0.3728\n",
            "epoch 3 step 200/638 loss 0.3729\n",
            "epoch 3 step 300/638 loss 0.3700\n",
            "epoch 3 step 400/638 loss 0.3675\n",
            "epoch 3 step 500/638 loss 0.3653\n",
            "epoch 3 step 600/638 loss 0.3597\n",
            "E3: acc=0.827 rec=0.598 f1=0.613 auc=0.859\n",
            "Best AUC: 0.8612871859239462\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install --upgrade grad-cam\n"
      ],
      "metadata": {
        "id": "CY8G1JW6ZDpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "import numpy as np, cv2\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# Choose a proper conv layer for ResNet18 (timm)\n",
        "target_layers = [model.layer4[-1].conv2]  # conv layer, not the whole block\n",
        "\n",
        "# Prepare one image\n",
        "sample_path = val_df.sample(1, random_state=0).iloc[0]['image_path']\n",
        "img = Image.open(sample_path).convert('RGB').resize((RES, RES))\n",
        "img_np = np.array(img).astype(np.float32) / 255.0\n",
        "\n",
        "# Transform (same as your val_tfms but keep a single tensor)\n",
        "x = val_tfms(img).unsqueeze(0)\n",
        "x = x.cuda()  # move to GPU\n",
        "\n",
        "# Initialize GradCAM (no use_cuda argument in new versions)\n",
        "cam = GradCAM(model=model, target_layers=target_layers)\n",
        "\n",
        "# Run CAM for the positive class (index 1 = Pneumonia)\n",
        "grayscale_cam = cam(input_tensor=x, targets=[ClassifierOutputTarget(1)])\n",
        "\n",
        "# Convert and overlay\n",
        "grayscale = grayscale_cam[0]  # first (and only) image in batch\n",
        "vis = show_cam_on_image(img_np, grayscale, use_rgb=True)\n",
        "cv2.imwrite('/content/cam_resnet18.png', cv2.cvtColor(vis, cv2.COLOR_RGB2BGR))\n",
        "'/content/cam_resnet18.png'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cLqt_T01YJim",
        "outputId": "4b875fd0-cdef-40c8-808c-f38fa85ab50f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/cam_resnet18.png'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "labels = ['Normal', 'Pneumonia']\n",
        "model.eval()\n",
        "\n",
        "def predict(img):\n",
        "    img = Image.fromarray(img).convert('RGB')\n",
        "    x = val_tfms(img).unsqueeze(0).cuda()\n",
        "    with torch.no_grad():\n",
        "        logits = model(x)\n",
        "        probs = torch.softmax(logits, dim=1).squeeze(0).cpu().numpy()\n",
        "    return {labels[i]: float(probs[i]) for i in range(2)}\n",
        "\n",
        "demo = gr.Interface(fn=predict, inputs=gr.Image(type='numpy'), outputs=gr.Label(num_top_classes=2), title='Pneumonia Detector (ResNet18)')\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "r8jLdTbTcExK",
        "outputId": "f9f16872-ec12-411b-ea08-f22107af349d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://02dad1af5153c58e45.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://02dad1af5153c58e45.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os; os.path.exists('/content/best_resnet18.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCNXYalldLIG",
        "outputId": "add52ea5-6488-44a3-9a5b-639fcc2dffb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timm, torch, torch.nn as nn\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "\n",
        "num_classes = 2\n",
        "model = timm.create_model('resnet18', pretrained=False, num_classes=num_classes).cuda()\n",
        "model.load_state_dict(torch.load('/content/best_resnet18.pth', map_location='cuda'))\n",
        "model.eval()\n",
        "\n",
        "RES = 224\n",
        "val_tfms = transforms.Compose([\n",
        "    transforms.Resize((RES, RES)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.25,0.25,0.25]),\n",
        "])\n",
        "\n",
        "sample_path = val_df.sample(1, random_state=0).iloc[0]['image_path']\n",
        "img = Image.open(sample_path).convert('RGB')\n",
        "x = val_tfms(img).unsqueeze(0).cuda()\n",
        "with torch.no_grad():\n",
        "    probs = torch.softmax(model(x), dim=1).squeeze(0).cpu().numpy()\n",
        "print({'Normal': float(probs[0]), 'Pneumonia': float(probs[1])})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kS5JqtmdOCp",
        "outputId": "5c1e6939-1603-47d7-9583-ef9559ee5c9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Normal': 0.8946426510810852, 'Pneumonia': 0.105357326567173}\n"
          ]
        }
      ]
    }
  ]
}