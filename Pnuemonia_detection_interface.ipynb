{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UPZEtUckU4uu",
    "outputId": "58bd823f-e0c4-4f48-e45b-d0fdcdbc28b1"
   },
   "outputs": [],
   "source": [
    "!pip -q install torch torchvision --extra-index-url https://download.pytorch.org/whl/cu121\n",
    "!pip -q install transformers datasets accelerate timm\n",
    "!pip -q install kaggle pydicom pillow opencv-python scikit-learn matplotlib seaborn grad-cam gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n-ynIjEYVeVW",
    "outputId": "0e47076f-c6e8-4efb-ea5f-6e16054601fb"
   },
   "outputs": [],
   "source": [
    "import torch; torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "id": "Um2qnIkf0m_U",
    "outputId": "39a7b61a-011f-48c7-8950-3c7281dae429"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c7yCHfyaVx6N"
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "os.makedirs('/root/.kaggle', exist_ok=True)\n",
    "shutil.move('/content/kaggle.json', '/root/.kaggle/kaggle.json')\n",
    "os.chmod('/root/.kaggle/kaggle.json', 0o600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1_ECxVijV9SL",
    "outputId": "619dd7f1-381e-4e6c-e5e3-a09529dc716c"
   },
   "outputs": [],
   "source": [
    "!kaggle competitions download -c rsna-pneumonia-detection-challenge -p /content/rsna\n",
    "import zipfile, glob\n",
    "for z in glob.glob('/content/rsna/*.zip'):\n",
    "    with zipfile.ZipFile(z, 'r') as zip_ref:\n",
    "        zip_ref.extractall('/content/rsna')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cg8RSkJ8WdTr",
    "outputId": "96e956aa-71ea-470d-a035-450684866fb6"
   },
   "outputs": [],
   "source": [
    "!pip -q install pydicom\n",
    "\n",
    "import pandas as pd, numpy as np, os, cv2, pydicom\n",
    "from tqdm import tqdm\n",
    "\n",
    "DICOM_DIR = '/content/rsna/stage_2_train_images'\n",
    "LABELS_CSV = '/content/rsna/stage_2_train_labels.csv'\n",
    "OUT_DIR = '/content/rsna_png'\n",
    "os.makedirs(f'{OUT_DIR}/images', exist_ok=True)\n",
    "\n",
    "labels = pd.read_csv(LABELS_CSV)\n",
    "img_labels = labels.groupby('patientId')['Target'].max().reset_index()\n",
    "img_labels['label'] = img_labels['Target'].astype(int)\n",
    "img_labels = img_labels[['patientId','label']]\n",
    "\n",
    "# LIMIT to a manageable subset first (adjust up later)\n",
    "MAX_IMAGES = 12000  # try 4000 if still OOM; 12000 if stable\n",
    "img_labels = img_labels.sample(n=min(MAX_IMAGES, len(img_labels)), random_state=42)\n",
    "\n",
    "# Low resolution to save memory; try (160,160) or (128,128) if still OOM\n",
    "RES = 160\n",
    "\n",
    "def dicom_to_png(path, size=(RES, RES)):\n",
    "    d = pydicom.dcmread(path)\n",
    "    arr = d.pixel_array.astype(np.float32)\n",
    "    # normalize 0-255\n",
    "    arr -= arr.min()\n",
    "    if arr.max() > 0:\n",
    "        arr /= arr.max()\n",
    "    arr = (arr * 255.0).clip(0,255).astype(np.uint8)\n",
    "    arr = cv2.resize(arr, size, interpolation=cv2.INTER_AREA)\n",
    "    img3 = np.stack([arr, arr, arr], axis=-1)\n",
    "    return img3\n",
    "\n",
    "paths, ys = [], []\n",
    "for pid, y in tqdm(img_labels.values):\n",
    "    p = os.path.join(DICOM_DIR, f'{pid}.dcm')\n",
    "    if not os.path.exists(p):\n",
    "        continue\n",
    "    img = dicom_to_png(p)\n",
    "    outp = os.path.join(OUT_DIR, 'images', f'{pid}.png')\n",
    "    cv2.imwrite(outp, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
    "    paths.append(outp)\n",
    "    ys.append(int(y))\n",
    "\n",
    "meta = pd.DataFrame({'image_path': paths, 'label': ys})\n",
    "meta.to_csv(f'{OUT_DIR}/train_meta.csv', index=False)\n",
    "meta['label'].value_counts(), len(meta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p2NU09CNXTX0",
    "outputId": "15e2d997-eeca-408d-cdc0-ec458cbefaba"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import pandas as pd\n",
    "\n",
    "meta = pd.read_csv('/content/rsna_png/train_meta.csv')\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.15, random_state=42)\n",
    "train_idx, val_idx = next(sss.split(meta['image_path'], meta['label']))\n",
    "train_df = meta.iloc[train_idx].reset_index(drop=True)\n",
    "val_df = meta.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "ds_train = Dataset.from_pandas(train_df)\n",
    "ds_val = Dataset.from_pandas(val_df)\n",
    "len(ds_train), len(ds_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237,
     "referenced_widgets": [
      "4b3846fd2e9a49b6bc3a9b5ce45a2a44",
      "387af9a8e1bb40dca49a0ac173398e54",
      "4a1e2b5f10ff4ddba5b78ae10bdd2343",
      "c7625b1f7ac043bb95b4ec2cdc4a0a1e",
      "81c970c09cb44b3ca5f83e715110872c",
      "4fbed99a610145bc95b8bcb15d91b344",
      "395f1f22e2e6435aabd10fc873a6ee1f",
      "4298047124fd48a49f2d059164cd25ef",
      "989230ee1b3d4f8c8f234d9ec4c82315",
      "87b437c3eda94598afda73aeac6e5994",
      "40ddb15c35a24f0789ac10724ff6e573",
      "d7abf1c449ea46f1847da8d91c7fcaa3",
      "0af5426f97534b729eb8e83efba43ece",
      "a0a3e345a80b49d4918b66800447bdbb",
      "d29b4814d21c46349f0a00e1919097d8",
      "3c8589f9c7e94b01ba68cac814593b7d",
      "e7227f8097ac41d3a17043d700e2e0be",
      "e8d68eeef9dd424badec81c555f6b628",
      "d8c1904b2ad14b4b8e88fbcfd2424032",
      "82d8bdddecae4f0080ee4638c25ba141",
      "bf2c56d58cbd44698ae9d76b57344e1f",
      "96427932e919417291c6b3b469fb13ab",
      "2d59e27e91444eb986ff1311dc27209a",
      "3c574e21b36c4fc9af38a415e476f91e",
      "100e36782a8744adaf740a73e7780c68",
      "e8412db0b458401c8d17fb0dc2251a62",
      "57145760371545bf9c80b7d957a0115f",
      "b3d86b4debd1409a925ee811cb73017a",
      "11ad9a000cf84b778c886aefb1c7607c",
      "2d1125794c4d4270b8d503b5cd7f8cd9",
      "6df7a56ba0724cada96de14232cc8e39",
      "70781622a5b0435b852fc59b4a05f7fc",
      "3d13d0b2cc194b6d8adc126dfd2ef5ae"
     ]
    },
    "id": "T_uyRIdTXZQp",
    "outputId": "3e5ca36c-b0c8-46e1-f6c2-df05057a8a6a"
   },
   "outputs": [],
   "source": [
    "import timm, torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# Image transforms (match RES)\n",
    "RES = 224  # set same as preprocessing\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.Resize((RES, RES)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.25,0.25,0.25])\n",
    "])\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.Resize((RES, RES)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.25,0.25,0.25])\n",
    "])\n",
    "\n",
    "# Lazy loader functions\n",
    "def load_image(example):\n",
    "    example['image'] = example['image_path']\n",
    "    return example\n",
    "\n",
    "ds_train = ds_train.map(load_image)\n",
    "ds_val = ds_val.map(load_image)\n",
    "\n",
    "# Minimal collate to load+transform per batch\n",
    "def collate_fn(batch, train=True):\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    for ex in batch:\n",
    "        img = Image.open(ex['image']).convert('RGB')\n",
    "        img = (train_tfms if train else val_tfms)(img)\n",
    "        imgs.append(img)\n",
    "        labels.append(int(ex['label']))\n",
    "    return {'pixel_values': torch.stack(imgs), 'labels': torch.tensor(labels, dtype=torch.long)}\n",
    "\n",
    "# Model\n",
    "num_classes = 2\n",
    "model = timm.create_model('resnet18', pretrained=True, num_classes=num_classes)\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QgfAssoQXknV",
    "outputId": "e221b958-fc21-4f67-d8cd-0f38a0396275"
   },
   "outputs": [],
   "source": [
    "import math, numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "\n",
    "BATCH = 16  # try 16; if OOM, set 8 or 4\n",
    "ACCUM = 2   # gradient accumulation steps (effective batch = BATCH*ACCUM)\n",
    "EPOCHS = 3\n",
    "LR = 3e-4\n",
    "\n",
    "\n",
    "train_loader = DataLoader(ds_train, batch_size=BATCH, shuffle=True, collate_fn=lambda x: collate_fn(x, True), num_workers=2, pin_memory=True)\n",
    "val_loader   = DataLoader(ds_val,   batch_size=BATCH, shuffle=False, collate_fn=lambda x: collate_fn(x, False), num_workers=2, pin_memory=True)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-2)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS*len(train_loader))\n",
    "\n",
    "\n",
    "best_auc = -1\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    running_loss = 0.0\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        x = batch['pixel_values'].cuda(non_blocking=True)\n",
    "        y = batch['labels'].cuda(non_blocking=True)\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y) / ACCUM\n",
    "        loss.backward()\n",
    "        if (step+1) % ACCUM == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            scheduler.step()\n",
    "        running_loss += loss.item() * ACCUM\n",
    "        if (step+1) % 100 == 0:\n",
    "            print(f\"epoch {epoch+1} step {step+1}/{len(train_loader)} loss {running_loss/(step+1):.4f}\")\n",
    "\n",
    "\n",
    "    # Eval\n",
    "    model.eval()\n",
    "    all_probs, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x = batch['pixel_values'].cuda(non_blocking=True)\n",
    "            y = batch['labels'].cuda(non_blocking=True)\n",
    "            logits = model(x)\n",
    "            probs = torch.softmax(logits, dim=1)[:,1].detach().cpu().numpy()\n",
    "            all_probs.append(probs)\n",
    "            all_labels.append(y.detach().cpu().numpy())\n",
    "    all_probs = np.concatenate(all_probs)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    preds = (all_probs >= 0.5).astype(int)\n",
    "    acc = accuracy_score(all_labels, preds)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(all_labels, preds, average='binary')\n",
    "    try:\n",
    "        auc = roc_auc_score(all_labels, all_probs)\n",
    "    except:\n",
    "        auc = float('nan')\n",
    "    print(f\"E{epoch+1}: acc={acc:.3f} rec={rec:.3f} f1={f1:.3f} auc={auc:.3f}\")\n",
    "    if auc > best_auc:\n",
    "        best_auc = auc\n",
    "        torch.save(model.state_dict(), '/content/best_resnet18.pth')\n",
    "print('Best AUC:', best_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CY8G1JW6ZDpU"
   },
   "outputs": [],
   "source": [
    "!pip -q install --upgrade grad-cam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "cLqt_T01YJim",
    "outputId": "45a11643-ec41-4c04-d9b1-90afde197199"
   },
   "outputs": [],
   "source": [
    "\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "import numpy as np, cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Choose a proper conv layer for ResNet18 (timm)\n",
    "target_layers = [model.layer4[-1].conv2]  # conv layer, not the whole block\n",
    "\n",
    "# Prepare one image\n",
    "sample_path = val_df.sample(1, random_state=0).iloc[0]['image_path']\n",
    "img = Image.open(sample_path).convert('RGB').resize((RES, RES))\n",
    "img_np = np.array(img).astype(np.float32) / 255.0\n",
    "\n",
    "# Transform (same as your val_tfms but keep a single tensor)\n",
    "x = val_tfms(img).unsqueeze(0)\n",
    "x = x.cuda()  # move to GPU\n",
    "\n",
    "# Initialize GradCAM (no use_cuda argument in new versions)\n",
    "cam = GradCAM(model=model, target_layers=target_layers)\n",
    "\n",
    "# Run CAM for the positive class (index 1 = Pneumonia)\n",
    "grayscale_cam = cam(input_tensor=x, targets=[ClassifierOutputTarget(1)])\n",
    "\n",
    "# Convert and overlay\n",
    "grayscale = grayscale_cam[0]  # first (and only) image in batch\n",
    "vis = show_cam_on_image(img_np, grayscale, use_rgb=True)\n",
    "cv2.imwrite('/content/cam_resnet18.png', cv2.cvtColor(vis, cv2.COLOR_RGB2BGR))\n",
    "'/content/cam_resnet18.png'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 611
    },
    "id": "r8jLdTbTcExK",
    "outputId": "f69136a9-5f38-49bb-9292-af2913fdd946"
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "labels = ['Normal', 'Pneumonia']\n",
    "model.eval()\n",
    "\n",
    "def predict(img):\n",
    "    img = Image.fromarray(img).convert('RGB')\n",
    "    x = val_tfms(img).unsqueeze(0).cuda()\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)\n",
    "        probs = torch.softmax(logits, dim=1).squeeze(0).cpu().numpy()\n",
    "    return {labels[i]: float(probs[i]) for i in range(2)}\n",
    "\n",
    "demo = gr.Interface(fn=predict, inputs=gr.Image(type='numpy'), outputs=gr.Label(num_top_classes=2), title='Pneumonia Detector (ResNet18)')\n",
    "demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uCNXYalldLIG",
    "outputId": "3b2a329b-9c77-4baf-d6da-92965f306be9"
   },
   "outputs": [],
   "source": [
    "import os; os.path.exists('/content/best_resnet18.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0kS5JqtmdOCp",
    "outputId": "4cff28b1-3597-4f46-d8ab-1608e9a15f6b"
   },
   "outputs": [],
   "source": [
    "import timm, torch, torch.nn as nn\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "num_classes = 2\n",
    "model = timm.create_model('resnet18', pretrained=False, num_classes=num_classes).cuda()\n",
    "model.load_state_dict(torch.load('/content/best_resnet18.pth', map_location='cuda'))\n",
    "model.eval()\n",
    "\n",
    "RES = 224\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.Resize((RES, RES)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.25,0.25,0.25]),\n",
    "])\n",
    "\n",
    "sample_path = val_df.sample(1, random_state=0).iloc[0]['image_path']\n",
    "img = Image.open(sample_path).convert('RGB')\n",
    "x = val_tfms(img).unsqueeze(0).cuda()\n",
    "with torch.no_grad():\n",
    "    probs = torch.softmax(model(x), dim=1).squeeze(0).cpu().numpy()\n",
    "print({'Normal': float(probs[0]), 'Pneumonia': float(probs[1])})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-pgYTltZu20W"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
